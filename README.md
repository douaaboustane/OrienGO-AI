project: Jobs Recommendation System
description: 
  Syst√®me de recommandation de m√©tiers bas√© sur le mod√®le RIASEC.
  Pr√©dit le m√©tier le plus adapt√© √† un √©tudiant √† partir de ses scores RIASEC,
  et lie le m√©tier √† une formation correspondante.

structure:
  data:
    - jobs.csv: Dataset m√©tiers (category, description, education, job_market, RIASEC scores, salary_range)
    - trainings.csv: Dataset formations (name, type, duration, description)
  models:
    - best_model.pkl: meilleur mod√®le sauvegard√©
    - encoder.pkl: encodeur des cat√©gories
    - scaler.pkl: normaliseur des donn√©es
  notebooks:
    - JobRecommendation.ipynb: entra√Ænement et tests
  utils:
    - preprocessing.py: pr√©traitement des donn√©es
  core.py: entra√Ænement et sauvegarde des mod√®les
  app.py: (optionnel) API Flask pour pr√©dictions
  requirements.txt: d√©pendances Python

models_used:
  - Logistic Regression (baseline)
  - Random Forest
  - KNN (K-Nearest Neighbors)
  - SVM (Support Vector Machine)

usage:
  training: |
    from utils.preprocessing import load_and_preprocess_data
    from core import train_models, save_best_model
    X_train, X_test, y_train, y_test, encoder, scaler = load_and_preprocess_data("data/jobs.csv")
    models = train_models(X_train, y_train)
    best_model_name, best_model = save_best_model(models, X_test, y_test, encoder, scaler)

  prediction: |
    import joblib, numpy as np
    model = joblib.load("models/best_model.pkl")
    scaler = joblib.load("models/scaler.pkl")
    encoder = joblib.load("models/encoder.pkl")
    student_profile = np.array([[10, 20, 30, 15, 100, 25]])
    student_profile_scaled = scaler.transform(student_profile)
    predicted_class = model.predict(student_profile_scaled)[0]
    predicted_job = encoder.inverse_transform([predicted_class])[0]
    print("üéØ M√©tier recommand√©:", predicted_job)

author: Douaa BOUSTANE

